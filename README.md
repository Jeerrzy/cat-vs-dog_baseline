[toc]

# Cat vs Dog Classification Competition：猫狗分类大赛！



:smile::smile:**:smile: <u>！！！为了庆祝2023年暑假开学而举办的:cat:VS:dog:猫狗分类大赛！！！</u>**:smile::smile::smile:

:moneybag::moneybag::moneybag: **奖金**

- **一等奖一名，奖金800元**
- **二等奖二名，奖金分别400元**
- **三等奖三名，奖金分别200元**

**要求：**

- <u>**评分方式：以`baseline`中`eval.py`得到的`f1_score`为准，越高越好**</u>

- 比赛时间结束时间暂定**<u>九月四日23：59</u>**(根据实际情况可能有调整)，届时<u>**以排名情况颁发奖金**</u>

- 假如有不止一个同学做得指标非常高或一致(指标精度只取到小数点后四位)，则<u>综合考虑创新性、报告写作水平</u>决定胜出者

- 建议有新提升的同学将自己的结果秀到群里(但不必说用了什么方法)，便于让大家了解最新进展

- **<u>最终提交的形式是写一篇简短的实验报告，说清楚做了哪些改进方法，以及最终取得f1_score的值是多少即可，发到我的邮箱</u>**

  **<u>注意写清楚姓名、学号、f1_score指标</u>**

- <u>确认获奖的同学会收到回复邮件，然后需要提交代码和最优模型的参数文件，以便复核</u>

- **<u>可以参考网络项目和代码，但不许相互抄袭</u>

- **<u>改进应根据baseline的结构进行</u>**(<u>包含数据集格式，代码组织格式等，在注释里有大量改进提示</u>)

  备注：此规则不是特别严格的限制，在baseline框架内部做些大的调整也可以，只要能解释清楚。

  主要目的在于防止出现拷贝成熟项目的情况。很多成熟项目已经包含了大量数据增强、训练优化策略，拿来比赛是降维打击，没有意义。

- 二分类问题是深度学习中最简单的任务，比赛主要为了大家锻炼和学习，获奖概率很大，欢迎同学们踊跃参加！

**:mortar_board::mortar_board::mortar_board: 举办方**

- 南京大学电子学院计算成像实验室

- 指导老师：沈秋

- 作者：金治宇 Jeerrzy

  联系邮箱：jzy@smail.nju.edu.cn
  
  

## Baseline指导

<u>baseline代码各个文件代码已经写了详细注释，请仔细阅读</u>

### 1.搭建环境

推荐先使用`conda`创建虚拟环境，然后在虚拟环境中安装依赖库

`baseline`中需要安装的核心库有三个`pytorch`、`opencv`、`matplotlib`

```python
conda create -n catvsdog python=3.10
conda activate catvsdog
conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
conda install matplotlib
pip install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple
```

<u>**一些提醒：**</u>

- 可以通过运行`predict.py`来验证搭建环境是否成功

- <u>遇到环境搭建失败的情况，请先在CSDN等平台自行搜索解决，一般都能找到办法</u>，常见操作包括：`conda`和`pip`切换安装，切换国内镜像源等
- 上述命令会安装最新版本的的`pytorch`。但最新版本不是强制要求，更低版本的`pytorch`更小，更容易安装，一般也可以运行。因为`pytorch`是一个维护得较为稳定的架构，各个版本间没有很大的修改。如果选择安装`pytorch`先前版本，请到官网上自行查询对应的`pip`或`conda`命令。
- 然而，对于使用英伟达30系显卡的同学，一定要安装`1.7`之后的新版本，这是因为30系显卡对应的`CUDA`驱动必须是`11.0`及以上的，而`pytorch 1.7`之后版本对应的`CUDA`驱动才有`11.0`以上。假如驱动不对应，程序运行时不会报错，而是卡着不动，这是很多同学都遇到过的一个很难找到原因的问题。更详细的请自行搜索<u>**“显卡、pytorch和cuda的对应关系”**</u>
- `AMD`显卡目前应该仍不支持`CUDA`计算的
- 没有显卡资源的同学可以试着使用CPU计算，如果计算时间在接受范围以内的话
- 资源实在无法支持运算的同学，请联系我获得服务器资源使用(学习使用服务器也需要时间成本，且不如本地计算调试方便，非必要不推荐)

### 2.数据集下载

训练所用的示例猫狗数据集在百度云下载。   
链接: https://pan.baidu.com/s/1hYBNG0TnGIeWw1-SwkzqpA     
提取码: ass8

datasets文件夹下存放的图片分为两部分，train里面是训练图片，test里面是测试图片。为了便于在训练时就能得到测试准确率，本数据集没有额外划分验证集，而是使用测试集作为验证集，在训练中每轮次都计算测试集精度，并自动保存指标最优的参数。

### 3.训练步骤

在训练前，需要首先准备好数据集。<u>**第一步，从百度网盘下载数据集并解压**</u>。其结构应该如下所示：

```
|-datasets
    |-train
        |-cat
            |-123.jpg
            |-234.jpg
            |-...
        |-dog
            |-345.jpg
            |-456.jpg
            |-...
        |-...
    |-test
        |-cat
            |-567.jpg
            |-678.jpg
            |-...
        |-dog
            |-789.jpg
            |-890.jpg
            |-...
        |-...
```
- <u>**第二步**</u>，在`config.py`中将`datasets_root`调整为自己存放数据集和路径，然后运行`database/generate_databse.py`，在`database`文件夹下生成`train.txt`和`test.txt` 则成功

  (这里请注意一下工作路径。该`py`文件应该是从`database`子文件夹的相对路径运行的，但是在少数情况下有的`vscode`编辑器会把运行路径统一定位到上层文件夹的情况，导致出现一些问题)

- **<u>第三步</u>**，在`config.py`中调节各项训练关键参数(记得调整完后运行保存为`json`文件)
- **<u>第四步</u>**，运行`train.py`，训练的关键信息和过程参数将保存在`logs/xxxx`文件下

### 4.测试步骤

- 在`config.py`中将`parameters_path`调整为<u>**自己训练中得到的最优参数**</u>(在`logs/xxxx/parameters`文件夹下生成)
- 执行`eval.py`

## 改进实验指导

提升性能指标的思路可能有如下几种。

### 1.自定义模型

使用特征提取能力更强的**主干特征提取模型**是提升性能最有效的办法，`lenet-5`是非常早期的神经网络，而从那时至今，又出现了大量更强大的神经网络。

<u>为了保证代码结构规范，使用自定义模型时，需要遵循如下做法</u>：

- 在`models`文件夹下建立`xxx.py`，存放定义模型的代码
- 在`models/__init__.py`下的`get_model`函数中，仿照给定方式拓展函数
- 要注意自定义模型的接口参数，如果需要拓展的话，可以在`config.py`中拓展，然后对接到`model`
- 这样做的好处是结构清晰，需要调整时在`config.py`中调参就可以快速切换模型, 而不是进入各个底层文件修改代码

### 2.数据预处理和增强

在许多实际任务中，由于数据稀少并存在大量噪声，数据处理方法对性能的影响甚至要大于模型。

考虑到本数据集比较丰富，信息较为简单，因此预处理方法影响不会那么大，但也会有效果，**<u>并且对提升最终锦上添花的一点点指标可能是决定性的。</u>**

数据预处理或增强的部分在`database/datasets.py`中定义：

- 为了不影响大家发挥，`baseline`除了对图像数据做了归一化和`reshape`外(在`self.transform`中定义)没有做任何预处理
- 其它可能的预处理方式有标准化(对均值和方差)，对原图图像切片，旋转，模糊等

### 3.关键计算方法或技巧

请注意正则化，BN层，激活函数，损失函数等计算方法对结果也可能有很大影响

### 4.调整超参数

训练中存在的大量超参数也是影响训练的关键，值得重点考虑的有如下几个：

- `input_shape`：输入尺度(将原图统一缩放到该尺度)

  一般来说，尺度越大，越接近原图，信息保留的越好，精度越高，但也会带来计算速度越慢。

  此外，缩放也具体有很多种方法，或许也是个值得探究的细节。

- `batch_size`：一批次并行输入的数据量

  一般来说，`batch_size`越大，数据的并行特征提取得越好，但对内存要求越高。

- `optimizer_type`：优化器种类

  不同优化器在优化策略、速度上都不一样，带来结果上的差异

- `lr`：学习率

  学习率越大，优化越快，但可能造成震荡，越小，优化越细致，但也可能造成速度过慢，并且陷入局部最优

- `epoch`：迭代轮次

  `epoch`越大，反复训练图像轮次越多，精度可能越高。但有时达到稳定后训练过多，不仅浪费时间，也有过拟合的风险、因此以达到最大值后持续一小段时间，可以确认没有上升空间，可以结束训练为最佳。

## 知识背景

### 1.关键基础概念的参考教材

包括学习、优化、训练、模型、前向传播、反向传播、损失函数、梯度下降等关键概念，无法一一赘述，请参考如下教材

- 关于机器学习中的基础概念：《机器学习》("西瓜书")
- 关于深度学习中的基础概念：《深度学习》("花书")
- 关于深度学习项目的实践方法：《动手学深度学习 pytorch版》 (作者：李沐)

### 2.分类任务中的指标评估问题

#### 混淆矩阵：**Confuse Matrix**

针对一个二分类问题，即将实例分成<u>正类(positive)</u>或<u>负类(negative)</u>，在实际分类中会出现以下四种情况：

- （1）若一个实例是正类，并且被预测为正类，即为真正类<u>TP(True Positive)</u>
- （2）若一个实例是正类，但是被预测为负类，即为假负类<u>FN(False Negative)</u>
- （3）若一个实例是负类，但是被预测为正类，即为假正类<u>FP(False Positive)</u>
- （4）若一个实例是负类，并且被预测为负类，即为真负类<u>TN(True Negative)</u>

|                | 预测为正类 | 预测为反类 |
| :------------: | :--------: | :--------: |
| **标签为正类** |     TP     |     FN     |
| **标签为反类** |     FP     |     TN     |

#### 准确率：Accuracy

<u>预测正确的</u>样本数量占总量的百分比
$$
Accuracy = \frac{TP+TN}{TP+TN+FN+FP}
$$
**该指标的缺点**：评估结果受数据样本分布影响很大

假如测试集有正样本99个，负样本1个。模型把所有的样本都预测为正样本，那么模型的Accuracy为99%

仅从评价指标看，模型的效果很好，但实际上模型没有任何预测能力

#### 精准率：Precision

在<u>模型预测为正样本</u>的结果中，正确结果所占的百分比，又称<u>查准率</u>
$$
Precision = \frac{TP}{TP+FP}
$$

#### 召回率：Recall

在<u>实际为正样本</u>的结果中，被模型正确预测所占的百分比，又称<u>查全率</u>
$$
Recall = \frac{TP}{TP+FN}
$$
分析：深度学习模型会对每一个任务对象计算得到**概率值<u>conf</u>**，然后设置**阈值<u>threshold</u>**，将概率值超过阈值的任务对象认定为正样本。

因此，**<u>threshold</u>**是一个对预测结果和指标影响非常大的<u>超参数</u>。**<u>thredshold</u>**的调整将对不同指标产生不同的影响。一般情况下，<u>**threshold**</u>增大时，**Precision**会增加，而**Recall**将会减少。

不难想象，查准率和查全率实际上构成了一对**<u>矛盾</u>**。举个栗子 :chestnut:，先假定一个背景：我们是警察，正在在抓捕罪犯，分类任务可以理解为：我们要从一群平民中区分谁是罪犯，谁是好人。那么，**<u>阈值threshold</u>**可以理解为：我们审讯和抓捕的严厉程度。查准率和查全率分别是两种办案的思路。其中，查准率要求要保证不误伤好人，原则是“宁可放过一千，不能抓错一个”，但查全率的要求是务必抓完所有罪犯，“宁可抓错一千，不能放过一个”。

#### F1-Score

**Precision**和**Recall**构成一组矛盾，此消彼长，很难用某一个来描述任务的性能

因此定义了**F1-Score**，对二者进行了调和、兼顾：
$$
F1 = \frac{2}{\frac{1}{P}+\frac{1}{R}}=\frac{2\times P\times R}{P+R}
$$
还是举个栗子 :chestnut:，假设有20个苹果:apple:，其中10个是好苹果，10个是坏苹果

- 如果某一模型，只预测得到了一个好苹果，其它全部是坏苹果

|                  | 预测为好苹果 | 预测为坏苹果 |
| :--------------: | :----------: | :----------: |
| **标签为好苹果** |      1       |      9       |
| **标签为坏苹果** |      0       |      10      |

那么简单计算可得到：$Precision=\frac{1}{1+0}=1.0$, $Recall=\frac{1}{1+9}=0.1$

可见，该模型的精度很高，但性能其实并不好，因为召回率很低

使用**F1-Score**进行兼顾，计算可得：$F1=\frac{2\times 1 \times 0.1}{1+0.1}\approx0.182$

### 3.一些可能的疑问和参考论文

对深度学习有兴趣的初学者，在做入门的图像分类任务时常常会产生以下疑问：

- 问：通过图像分类任务，我学习了卷积神经网络。但它好像是一个黑盒，看上去也是可以胡乱设计的，找不到什么规律。例如，对猫狗识别这个任务，我设置五层网络可以做，四层和六层好像也可以，区别不是很大。难道神经网络都是瞎设计，参数也都是瞎选的吗？

  答：如果只是以“能够跑通”为标准，只要保证数据维度不出错，神经网络确实可以胡乱设计，大部分都能跑通。<u>**但如果考虑精度和速度，不同结构的差异就体现出来了，而且其中显然有规律可循。这些规律也正是研究重点所在。**</u>

  例如，对于卷积神经网络来说，最重要的参数有两个：一是卷积层的深度，二是卷积核的尺寸。那么，这两个参数该怎么选才最佳呢？

  答案是主要根据任务特点决定。

  模型深度主要取决于信息的复杂度。<u>打比方说，模型深度和任务信息复杂度，就像杯子和水的关系。</u>杯子太小，水太多，就会接不住，水溢出来。而杯子太大，水太少，在杯底浅浅的一层，很难被人喝到。任务信息的多少不难判断。例如。对于一个房屋的房价预测问题，评估房屋的信息有大小、年份、地段等，大概只有几个到十几个离散数值，房价和这些信息存在简单的推导关系，这就属于信息很少或很浅的情况。而对于视觉类任务，图像的像素点是密集排列的，且很难直接根据某个像素点的值直接推导图像的高层信息，比如类别，因此<u>图像分类首先就是一个信息稠密、推导复杂</u>的任务，所以模型深度必须有一个底线作为保证。而具体复杂度是多少，还和图像尺度，复杂程度，任务层次等因素有关。例如，假如只是判断图像类别，就是最浅的一层。而进一步到图像内部的某些目标，就更复杂一些。再进一步到目标的动作，行为，就需要融合时序信息，则更加复杂。有丰富经验的人在了解数据情况和任务需求后，一般就可以形成大概认识了。

  卷积核的尺度也和任务特点有关。大的卷积核在大的空间上做运算，可以提取到更多大尺度的信息，而可能疏忽了局部小信息。小的卷积核有利于提取局部小信息，而看不到更大的全局信息。这个概念被称为“感受野”。此外，卷积核尺度的选取还要考虑参数量问题，参数越少，越有利于优化，计算成本越低，存储模型所需的内存也越小。

  关于卷积神经网路中深度和卷积核尺寸对性能影响的研究工作，实际上在神经网络发展的早期就完成了，其中最经典的论文是：

  《VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION》

  https://arxiv.org/abs/1409.1556

  也就是在这篇论文发表后，神经网络中都开始使用大量的`3*3`卷积核提取特征，而降维的工作用`pooling`层完成。因为两个`3*3`卷积核的参数比一个`5*5`的还要小，感受野却更大。此外`3*3`卷积核加上一个`padding`层可以保持特征图尺度不变，数据维度观察起来更加清晰。这都是这篇论文中的结论。

  有兴趣的同学可以阅读学习。

- 问：对于大数据集，神经网络越深越好吗？

  答：并不是。早期的神经网络有大量研究者试图通过堆深度解决一些复杂的图像问题，但是达到一定程度后精度反而会下降，这种现象被称为“模型退化”。这一度让研究者放弃了对大模型的幻想(直到最近的语言模型才又出现)。模型退化问题曾经困扰了深度学习领域很久，最终对这个的解决是著名的“残差结构”，提出这个结构的经典论文是：

  《Deep Residual Learning for Image Recognition》

  https://arxiv.org/abs/1512.03385

  有兴趣的同学可以阅读学习。

- 问：神经网络是万能的吗？我们能够通过设计一个很深的神经网络，将输出接到我们希望得到的信息上，再用大量数据训练，来解决世界上一切问题吗？

  答：这或许是有希望能够做到，但绝对不可能那么简单的。

  首先，神经网络并不是万能的，它往往要和大量先验知识和设计技巧结合使用。<u>打个比方说，神经网络或许可能能帮我们盖一座大楼，但是它没办法拿沙子和石子完成，至少也要我们把地基和脚手架打好。</u>或者说，神经网络往往很难做到我们理想的：
  $$
  我们想到得到的信息 = 通用神经网络(输入信息)
  $$
  而是：
  $$
  编码信息 = 预处理或特征编码(输入信息)\\
  解码信息 = 根据任务特点精心设计的神经网络(编码信息)\\
  我们想要得到的信息=后处理或特征解码(解码信息)
  $$
  目前许多研究希望解决这个问题，例如大语言模型。但我认为这很难一蹴而就，正如物理学统一场理论的难以实现。

  事实上，除了图像分类这种最简单的任务外，只要是稍微复杂些的任务，都能体现出这些特点。例如视觉领域的另一项基础任务：目标检测。

  有兴趣更进一步的同学，可以由分类任务出发，思考以下如何解决“目标检测”问题（即得到图片中某种动物的位置和类别信息，比起分类任务，目标检测的难度在于如何得到位置信息），然后阅读`Faster-RCNN`或`YOLO`的论文，仔细分析其信息处理过程和模型结构：

  《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》

  https://arxiv.org/pdf/1506.01497.pdf

  《You Only Look Once: Unified, Real-Time Object Detection》

  https://arxiv.org/abs/1506.02640

- 问：神经网络中的大量技巧(如正则化、激活函数)应该在什么时候使用？超参数该怎么调节？

  答：通过学习理论基础，可以有一些大概的把握，知道在什么情况下该怎么处理。

  例如，发现训练集损失值曲线一直下降，而验证集损失曲线先下降后上升，这是典型的过拟合情况。应该在模型中加入一些正则化操作，比如调整损失函数，加入`drop_out`层等。此外，针对不同的任务类型，可以使用不同的激活函数和损失函数。

  超参数的调节主要根据经验和实际情况，很难统一，<u>**深度学习本质就是经验主义和实验学科。**</u>

